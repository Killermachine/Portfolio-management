{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from scipy.stats import norm\n",
    "from gensim.models import word2vec\n",
    "# from kaggle.competitions import twosigmanews\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 55\n"
     ]
    }
   ],
   "source": [
    "cpu_count = 2*multiprocessing.cpu_count()-1\n",
    "print('Number of CPUs: {}'.format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "assert torch.cuda.is_available and torch.has_cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P40'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    '0':0, \n",
    "    '1':1, \n",
    "    '-1':2\n",
    "}\n",
    "# label_map_reverse = ['Neutral', 'Positive', 'Negative']\n",
    "label_map_reverse = [0, 1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.ReversibleField(sequential=True,\n",
    "                                      lower=True,\n",
    "                                      include_lengths=True,\n",
    "                                      batch_first=True)\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False, preprocessing=lambda x: label_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchtext.data.TabularDataset('news_val_torch.csv',format='csv', \n",
    "                                                    skip_header = True,\n",
    "                                                    fields=[('headline',TEXT),('sentimentClass',LABEL)])\n",
    "val_data = torchtext.data.TabularDataset('news_test_torch.csv',format='csv', \n",
    "                                                  skip_header = True,\n",
    "                                                  fields=[('headline',TEXT),('sentimentClass',LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = torchtext.data.TabularDataset(\"news_torch_experiment.csv\",format='csv', \n",
    "#                                                     skip_header = True,\n",
    "#                                                     fields=[('headline',TEXT),('sentimentClass',LABEL)])\n",
    "# val_data = torchtext.data.TabularDataset(\"news_torch_experiment.csv\",format='csv', \n",
    "#                                                   skip_header = True,\n",
    "#                                                   fields=[('headline',TEXT),('sentimentClass',LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, val_data, \n",
    "                 vectors=torchtext.vocab.Vectors(name='wiki-news-300d-1M.vec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torchtext.data.BucketIterator(train_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            sort_key=lambda x: data.interleave_keys(len(x.headline)),\n",
    "                                            device=torch.device('cuda'))\n",
    "test_iter = torchtext.data.BucketIterator(val_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            sort_key=lambda x: data.interleave_keys(len(x.headline)),\n",
    "                                            device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 0, 2, 2, 2, 2, 1, 1, 0, 0, 1, 1, 2, 2,\n",
      "        2, 0, 2, 2, 0, 2, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch.sentimentClass)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_iter, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    i = 0\n",
    "    for batch in test_iter:\n",
    "        pred = model(batch.headline)\n",
    "        outputs = F.softmax(pred, dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        loss = F.cross_entropy(pred, batch.sentimentClass)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        total += batch.sentimentClass.size(0)\n",
    "        correct += predicted.eq(batch.sentimentClass.view_as(predicted)).sum().item()\n",
    "        i+=1\n",
    "        if i > 100:\n",
    "            break\n",
    "#     return (100 * correct / total), test_loss/len(test_iter)\n",
    "    return (100 * correct / total), test_loss/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, num_classes, vocab, kernel_size=3, dropout=0):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        self.in_size, self.hidden_size = in_size, hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab.vectors.shape[0],vocab.vectors.shape[1])\n",
    "        self.embedding.weight = torch.nn.Parameter(self.vocab.vectors, requires_grad=False)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_size, hidden_size, kernel_size=kernel_size, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=kernel_size, padding=1)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(int(hidden_size), self.num_classes)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        data = self.embedding(data[0])\n",
    "        hidden = self.conv1(data.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(hidden.shape[0], hidden.shape[1], hidden.size(-1))\n",
    "#         hidden = nn.dropout(hidden)\n",
    "        hidden = self.conv2(hidden.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(hidden.shape[0], hidden.shape[1], hidden.size(-1))\n",
    "        \n",
    "        hidden,_ = torch.max(hidden, dim=1)\n",
    "        pred = self.linear(hidden)\n",
    "        pred = torch.tanh(pred)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/4], Step: [5001/45466], Trn Acc: 0.00, Val Acc: 70.85, Trn Loss: 0.80, Val Loss: 0.70\n",
      "Epoch: [1/4], Step: [10001/45466], Trn Acc: 0.00, Val Acc: 70.39, Trn Loss: 0.75, Val Loss: 0.70\n",
      "Epoch: [1/4], Step: [15001/45466], Trn Acc: 0.00, Val Acc: 71.10, Trn Loss: 0.74, Val Loss: 0.68\n",
      "Epoch: [1/4], Step: [20001/45466], Trn Acc: 0.00, Val Acc: 73.45, Trn Loss: 0.73, Val Loss: 0.65\n",
      "Epoch: [1/4], Step: [25001/45466], Trn Acc: 0.00, Val Acc: 70.76, Trn Loss: 0.72, Val Loss: 0.69\n",
      "Epoch: [1/4], Step: [30001/45466], Trn Acc: 0.00, Val Acc: 72.56, Trn Loss: 0.72, Val Loss: 0.66\n",
      "Epoch: [1/4], Step: [35001/45466], Trn Acc: 0.00, Val Acc: 72.37, Trn Loss: 0.72, Val Loss: 0.67\n",
      "Epoch: [1/4], Step: [40001/45466], Trn Acc: 0.00, Val Acc: 73.30, Trn Loss: 0.71, Val Loss: 0.67\n",
      "Epoch: [1/4], Step: [45001/45466], Trn Acc: 0.00, Val Acc: 73.70, Trn Loss: 0.71, Val Loss: 0.65\n",
      "Epoch: [2/4], Step: [5001/45466], Trn Acc: 0.00, Val Acc: 72.52, Trn Loss: 0.70, Val Loss: 0.66\n",
      "Epoch: [2/4], Step: [10001/45466], Trn Acc: 0.00, Val Acc: 73.27, Trn Loss: 0.70, Val Loss: 0.65\n",
      "Epoch: [2/4], Step: [15001/45466], Trn Acc: 0.00, Val Acc: 73.33, Trn Loss: 0.70, Val Loss: 0.67\n",
      "Epoch: [2/4], Step: [20001/45466], Trn Acc: 0.00, Val Acc: 72.90, Trn Loss: 0.70, Val Loss: 0.67\n",
      "Epoch: [2/4], Step: [25001/45466], Trn Acc: 0.00, Val Acc: 70.76, Trn Loss: 0.70, Val Loss: 0.68\n",
      "Epoch: [2/4], Step: [30001/45466], Trn Acc: 0.00, Val Acc: 71.63, Trn Loss: 0.70, Val Loss: 0.67\n",
      "Epoch: [2/4], Step: [35001/45466], Trn Acc: 0.00, Val Acc: 74.94, Trn Loss: 0.70, Val Loss: 0.64\n",
      "Epoch: [2/4], Step: [40001/45466], Trn Acc: 0.00, Val Acc: 72.46, Trn Loss: 0.70, Val Loss: 0.67\n",
      "Epoch: [2/4], Step: [45001/45466], Trn Acc: 0.00, Val Acc: 72.46, Trn Loss: 0.70, Val Loss: 0.66\n",
      "Epoch: [3/4], Step: [5001/45466], Trn Acc: 0.00, Val Acc: 74.07, Trn Loss: 0.69, Val Loss: 0.66\n",
      "Epoch: [3/4], Step: [10001/45466], Trn Acc: 0.00, Val Acc: 74.97, Trn Loss: 0.69, Val Loss: 0.63\n",
      "Epoch: [3/4], Step: [15001/45466], Trn Acc: 0.00, Val Acc: 73.48, Trn Loss: 0.69, Val Loss: 0.66\n",
      "Epoch: [3/4], Step: [20001/45466], Trn Acc: 0.00, Val Acc: 73.21, Trn Loss: 0.69, Val Loss: 0.66\n",
      "Epoch: [3/4], Step: [25001/45466], Trn Acc: 0.00, Val Acc: 75.19, Trn Loss: 0.69, Val Loss: 0.64\n",
      "Epoch: [3/4], Step: [30001/45466], Trn Acc: 0.00, Val Acc: 73.48, Trn Loss: 0.69, Val Loss: 0.66\n",
      "Epoch: [3/4], Step: [35001/45466], Trn Acc: 0.00, Val Acc: 74.60, Trn Loss: 0.69, Val Loss: 0.65\n",
      "Epoch: [3/4], Step: [40001/45466], Trn Acc: 0.00, Val Acc: 72.80, Trn Loss: 0.69, Val Loss: 0.66\n",
      "Epoch: [3/4], Step: [45001/45466], Trn Acc: 0.00, Val Acc: 74.54, Trn Loss: 0.69, Val Loss: 0.66\n",
      "Epoch: [4/4], Step: [5001/45466], Trn Acc: 0.00, Val Acc: 74.26, Trn Loss: 0.67, Val Loss: 0.64\n",
      "Epoch: [4/4], Step: [10001/45466], Trn Acc: 0.00, Val Acc: 74.07, Trn Loss: 0.68, Val Loss: 0.65\n",
      "Epoch: [4/4], Step: [15001/45466], Trn Acc: 0.00, Val Acc: 73.61, Trn Loss: 0.68, Val Loss: 0.66\n",
      "Epoch: [4/4], Step: [20001/45466], Trn Acc: 0.00, Val Acc: 73.82, Trn Loss: 0.68, Val Loss: 0.67\n",
      "Epoch: [4/4], Step: [25001/45466], Trn Acc: 0.00, Val Acc: 71.91, Trn Loss: 0.68, Val Loss: 0.67\n",
      "Epoch: [4/4], Step: [30001/45466], Trn Acc: 0.00, Val Acc: 73.98, Trn Loss: 0.68, Val Loss: 0.65\n",
      "Epoch: [4/4], Step: [35001/45466], Trn Acc: 0.00, Val Acc: 72.74, Trn Loss: 0.68, Val Loss: 0.66\n",
      "Epoch: [4/4], Step: [40001/45466], Trn Acc: 0.00, Val Acc: 73.79, Trn Loss: 0.68, Val Loss: 0.66\n",
      "Epoch: [4/4], Step: [45001/45466], Trn Acc: 0.00, Val Acc: 74.23, Trn Loss: 0.68, Val Loss: 0.65\n"
     ]
    }
   ],
   "source": [
    "model = NN(in_size=300, hidden_size=300, num_classes=3, vocab=TEXT.vocab, kernel_size=3)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (batch) in enumerate(train_iter):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch.headline)\n",
    "        loss = F.cross_entropy(pred,batch.sentimentClass)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        val_period = 5000\n",
    "        if i > 0 and i % val_period == 0:\n",
    "            # validate\n",
    "            model.eval()\n",
    "#             trn_acc, trn_loss = test_model(snli_train_iter_for_val, model)\n",
    "#             trn_acc = None\n",
    "            val_acc, val_loss = test_model(test_iter, model)\n",
    "    \n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Trn Acc: {:.2f}, Val Acc: {:.2f}, Trn Loss: {:.2f}, Val Loss: {:.2f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, len(train_iter), 0, val_acc,\n",
    "                          running_loss/val_period, val_loss))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64195\n",
      "2054224\n"
     ]
    }
   ],
   "source": [
    "test_iter_pred = torchtext.data.BucketIterator(val_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False,\n",
    "#                                             sort_key=lambda x: data.interleave_keys(len(x.headline)),\n",
    "                                            device=torch.device('cuda'))\n",
    "print(len(test_iter_pred))\n",
    "pred_total = []\n",
    "model.eval()\n",
    "for batch in test_iter_pred:\n",
    "    pred = model(batch.headline)\n",
    "    outputs = F.softmax(pred, dim=1)\n",
    "    pred = outputs.max(1, keepdim=True)[1]\n",
    "#     pred = pred.cpu().numpy().reshape(test_iter_pred.batch_size)\n",
    "    pred = pred.cpu().numpy().reshape(len(pred))\n",
    "    pred = list(map(lambda x: label_map_reverse[x], pred))\n",
    "    pred_total.extend(pred)\n",
    "print(len(pred_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pred_total\",pred_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, 1, 1, 1, 0, -1, 0, 0, 0]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_total[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"news_train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df = news_df[ (news_df['time']>='2015-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2054224"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yz4499/miniconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "news_test_df['pred'] = pd.Series(pred_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df = news_test_df.assign(pred=pd.Series(pred_total).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assetCodes</th>\n",
       "      <th>assetName</th>\n",
       "      <th>pred</th>\n",
       "      <th>headline</th>\n",
       "      <th>time</th>\n",
       "      <th>sentimentNegative</th>\n",
       "      <th>sentimentNeutral</th>\n",
       "      <th>sentimentPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7274526</th>\n",
       "      <td>{'LONG.O'}</td>\n",
       "      <td>eLong Inc</td>\n",
       "      <td>-1</td>\n",
       "      <td>Beijing Court Rules in Favor of eLong in Dispu...</td>\n",
       "      <td>2015-01-01 00:00:04+00:00</td>\n",
       "      <td>0.809405</td>\n",
       "      <td>0.129914</td>\n",
       "      <td>0.060681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274527</th>\n",
       "      <td>{'EXPE.O', 'EXPE.OQ'}</td>\n",
       "      <td>Expedia Inc</td>\n",
       "      <td>-1</td>\n",
       "      <td>Beijing Court Rules in Favor of eLong in Dispu...</td>\n",
       "      <td>2015-01-01 00:00:04+00:00</td>\n",
       "      <td>0.819121</td>\n",
       "      <td>0.125242</td>\n",
       "      <td>0.055638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274528</th>\n",
       "      <td>{'SYX.N'}</td>\n",
       "      <td>Systemax Inc</td>\n",
       "      <td>1</td>\n",
       "      <td>SYSTEMAX'S GLOBAL INDUSTRIAL BUSINESS SIGNS DE...</td>\n",
       "      <td>2015-01-01 00:23:05+00:00</td>\n",
       "      <td>0.034652</td>\n",
       "      <td>0.122020</td>\n",
       "      <td>0.843328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274529</th>\n",
       "      <td>{'SYX.N'}</td>\n",
       "      <td>Systemax Inc</td>\n",
       "      <td>1</td>\n",
       "      <td>Systemax's Global Industrial Business Signs De...</td>\n",
       "      <td>2015-01-01 00:23:07+00:00</td>\n",
       "      <td>0.097430</td>\n",
       "      <td>0.156117</td>\n",
       "      <td>0.746453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274530</th>\n",
       "      <td>{'BRO.N'}</td>\n",
       "      <td>Brown &amp; Brown Inc</td>\n",
       "      <td>1</td>\n",
       "      <td>Brown &amp; Brown, Inc. Announces Sale of Certain ...</td>\n",
       "      <td>2015-01-01 00:30:00+00:00</td>\n",
       "      <td>0.552344</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.199656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    assetCodes          assetName  pred  \\\n",
       "7274526             {'LONG.O'}          eLong Inc    -1   \n",
       "7274527  {'EXPE.O', 'EXPE.OQ'}        Expedia Inc    -1   \n",
       "7274528              {'SYX.N'}       Systemax Inc     1   \n",
       "7274529              {'SYX.N'}       Systemax Inc     1   \n",
       "7274530              {'BRO.N'}  Brown & Brown Inc     1   \n",
       "\n",
       "                                                  headline  \\\n",
       "7274526  Beijing Court Rules in Favor of eLong in Dispu...   \n",
       "7274527  Beijing Court Rules in Favor of eLong in Dispu...   \n",
       "7274528  SYSTEMAX'S GLOBAL INDUSTRIAL BUSINESS SIGNS DE...   \n",
       "7274529  Systemax's Global Industrial Business Signs De...   \n",
       "7274530  Brown & Brown, Inc. Announces Sale of Certain ...   \n",
       "\n",
       "                              time  sentimentNegative  sentimentNeutral  \\\n",
       "7274526  2015-01-01 00:00:04+00:00           0.809405          0.129914   \n",
       "7274527  2015-01-01 00:00:04+00:00           0.819121          0.125242   \n",
       "7274528  2015-01-01 00:23:05+00:00           0.034652          0.122020   \n",
       "7274529  2015-01-01 00:23:07+00:00           0.097430          0.156117   \n",
       "7274530  2015-01-01 00:30:00+00:00           0.552344          0.248000   \n",
       "\n",
       "         sentimentPositive  \n",
       "7274526           0.060681  \n",
       "7274527           0.055638  \n",
       "7274528           0.843328  \n",
       "7274529           0.746453  \n",
       "7274530           0.199656  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df = news_test_df[['assetCodes', \n",
    "                    'assetName', \n",
    "                    'pred', \n",
    "                    'headline',\n",
    "                    'time',\n",
    "                    'sentimentNegative',\n",
    "                    'sentimentNeutral',\n",
    "                    'sentimentPositive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df.to_csv('news_test_pred_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"news_val_torch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "news_train_df, news_val_df = train_test_split(news_df, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_val_df.to_csv(\"news_torch_experiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>sentimentClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1281950</th>\n",
       "      <td>CORRECTED-UPDATE 1-Snowden's father criticizes...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917675</th>\n",
       "      <td>Quarterly Results and Earnings Call Schedules,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829658</th>\n",
       "      <td>TEXT-S&amp;P release on Fannie Mae, Freddie Mac</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051799</th>\n",
       "      <td>COMSTOCK-ON FEB 29, CLOSED ON SALE OF SOME OF ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233417</th>\n",
       "      <td>RPT-MCDONALD'S &lt;MCD.N&gt; CFO SAYS TO RE-IMAGE 1,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  headline  sentimentClass\n",
       "1281950  CORRECTED-UPDATE 1-Snowden's father criticizes...              -1\n",
       "917675   Quarterly Results and Earnings Call Schedules,...               1\n",
       "829658         TEXT-S&P release on Fannie Mae, Freddie Mac               0\n",
       "1051799  COMSTOCK-ON FEB 29, CLOSED ON SALE OF SOME OF ...               0\n",
       "1233417  RPT-MCDONALD'S <MCD.N> CFO SAYS TO RE-IMAGE 1,...               0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"news_train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df[['headline',\n",
    "                   'sentimentClass',\n",
    "                   'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df = news_df[ (news_df['time']>='2015-01-01')]\n",
    "news_train_df = news_df[ (news_df['time']<'2015-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df = news_test_df[['headline',\n",
    "                             'sentimentClass']]\n",
    "news_train_df = news_train_df[['headline',\n",
    "                               'sentimentClass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "news_train_df, news_val_df = train_test_split(news_train_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train_df.to_csv('news_train_torch.csv', index=False)\n",
    "news_val_df.to_csv('news_val_torch.csv', index=False)\n",
    "news_test_df.to_csv('news_test_torch.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"news_train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df[['assetCodes', \n",
    "                    'assetName', \n",
    "                    'sentimentClass', \n",
    "                    'headline',\n",
    "                    'time',\n",
    "                    'sentimentNegative',\n",
    "                    'sentimentNeutral',\n",
    "                    'sentimentPositive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>sentimentClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China's Daqing pumps 43.41 mln tonnes of oil i...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEATURE-In kidnapping, finesse works best</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRESS DIGEST - Wall Street Journal - Jan 1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  sentimentClass\n",
       "0  China's Daqing pumps 43.41 mln tonnes of oil i...              -1\n",
       "1          FEATURE-In kidnapping, finesse works best              -1\n",
       "2         PRESS DIGEST - Wall Street Journal - Jan 1              -1\n",
       "3              PRESS DIGEST - New York Times - Jan 1              -1\n",
       "4              PRESS DIGEST - New York Times - Jan 1              -1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df = news_df[ (news_df['time']>='2015-01-01')]\n",
    "news_train_df = news_df[ (news_df['time']<'2015-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def genData(news_df):\n",
    "#     data = []\n",
    "#     target = []\n",
    "#     for index, row in news_df.iterrows():\n",
    "#         data.append(row['headline'])\n",
    "#         target.append([row['sentimentNegative'], row['sentimentNeutral'], row['sentimentPositive']])\n",
    "#     return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_targets = news_test_df['headline'].values.tolist(), \\\n",
    "                            news_test_df[['sentimentNegative', 'sentimentNeutral', 'sentimentPositive']].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "news_train_df_head = news_test_df.head(20000)\n",
    "# train_data, train_target = genData(news_train_df_head)\n",
    "train_data, train_targets = news_train_df_head['headline'].values.tolist(), \\\n",
    "                            news_train_df_head[['sentimentNegative', 'sentimentNeutral', 'sentimentPositive']].values.tolist()\n",
    "\n",
    "train_data, val_data, train_targets, val_targets = train_test_split(\n",
    "    train_data, train_targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #1 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d686ed0e91fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.6/site-packages/torchtext/data/example.py\u001b[0m in \u001b[0;36mfromlist\u001b[0;34m(cls, data, fields)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfromlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zip argument #1 must support iteration"
     ]
    }
   ],
   "source": [
    "torchtext.data.Example.fromlist(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
