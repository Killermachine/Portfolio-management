{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from scipy.stats import norm\n",
    "from gensim.models import word2vec\n",
    "# from kaggle.competitions import twosigmanews\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 55\n"
     ]
    }
   ],
   "source": [
    "cpu_count = 2*multiprocessing.cpu_count()-1\n",
    "print('Number of CPUs: {}'.format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "assert torch.cuda.is_available and torch.has_cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P40'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    '0':0, \n",
    "    '1':1, \n",
    "    '-1':2\n",
    "}\n",
    "label_map_reverse = ['Neutral', 'Positive', 'Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.ReversibleField(sequential=True,\n",
    "                                      lower=True,\n",
    "                                      include_lengths=True,\n",
    "                                      batch_first=True)\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False, preprocessing=lambda x: label_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchtext.data.TabularDataset('news_val_torch.csv',format='csv', \n",
    "                                                    skip_header = True,\n",
    "                                                    fields=[('headline',TEXT),('sentimentClass',LABEL)])\n",
    "val_data = torchtext.data.TabularDataset('news_test_torch.csv',format='csv', \n",
    "                                                  skip_header = True,\n",
    "                                                  fields=[('headline',TEXT),('sentimentClass',LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = torchtext.data.TabularDataset(\"news_torch_experiment.csv\",format='csv', \n",
    "#                                                     skip_header = True,\n",
    "#                                                     fields=[('headline',TEXT),('sentimentClass',LABEL)])\n",
    "# val_data = torchtext.data.TabularDataset(\"news_torch_experiment.csv\",format='csv', \n",
    "#                                                   skip_header = True,\n",
    "#                                                   fields=[('headline',TEXT),('sentimentClass',LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, val_data, \n",
    "                 vectors=torchtext.vocab.Vectors(name='wiki-news-300d-1M.vec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torchtext.data.BucketIterator(train_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            sort_key=lambda x: data.interleave_keys(len(x.headline)),\n",
    "                                            device=torch.device('cuda'))\n",
    "test_iter = torchtext.data.BucketIterator(val_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            sort_key=lambda x: data.interleave_keys(len(x.headline)),\n",
    "                                            device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 0, 2, 2, 2, 2, 1, 1, 0, 0, 1, 1, 2, 2,\n",
      "        2, 0, 2, 2, 0, 2, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch.sentimentClass)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_iter, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    i = 0\n",
    "    for batch in test_iter:\n",
    "        pred = model(batch.headline)\n",
    "        outputs = F.softmax(pred, dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        loss = F.cross_entropy(pred, batch.sentimentClass)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        total += batch.sentimentClass.size(0)\n",
    "        correct += predicted.eq(batch.sentimentClass.view_as(predicted)).sum().item()\n",
    "        i+=1\n",
    "        if i > 100:\n",
    "            break\n",
    "#     return (100 * correct / total), test_loss/len(test_iter)\n",
    "    return (100 * correct / total), test_loss/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, num_classes, vocab, kernel_size=3, dropout=0):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        self.in_size, self.hidden_size = in_size, hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab.vectors.shape[0],vocab.vectors.shape[1])\n",
    "        self.embedding.weight = torch.nn.Parameter(self.vocab.vectors, requires_grad=False)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_size, hidden_size, kernel_size=kernel_size, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=kernel_size, padding=1)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(int(hidden_size), self.num_classes)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        data = self.embedding(data[0])\n",
    "        hidden = self.conv1(data.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(hidden.shape[0], hidden.shape[1], hidden.size(-1))\n",
    "#         hidden = nn.dropout(hidden)\n",
    "        hidden = self.conv2(hidden.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(hidden.shape[0], hidden.shape[1], hidden.size(-1))\n",
    "        \n",
    "        hidden,_ = torch.max(hidden, dim=1)\n",
    "        pred = self.linear(hidden)\n",
    "        pred = torch.tanh(pred)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/20], Step: [1001/45466], Trn Acc: 0.00, Val Acc: 66.00, Trn Loss: 0.89, Val Loss: 0.79\n",
      "Epoch: [1/20], Step: [2001/45466], Trn Acc: 0.00, Val Acc: 67.26, Trn Loss: 0.82, Val Loss: 0.77\n",
      "Epoch: [1/20], Step: [3001/45466], Trn Acc: 0.00, Val Acc: 67.57, Trn Loss: 0.81, Val Loss: 0.75\n",
      "Epoch: [1/20], Step: [4001/45466], Trn Acc: 0.00, Val Acc: 68.19, Trn Loss: 0.80, Val Loss: 0.74\n",
      "Epoch: [1/20], Step: [5001/45466], Trn Acc: 0.00, Val Acc: 67.98, Trn Loss: 0.79, Val Loss: 0.74\n",
      "Epoch: [1/20], Step: [6001/45466], Trn Acc: 0.00, Val Acc: 70.02, Trn Loss: 0.79, Val Loss: 0.72\n",
      "Epoch: [1/20], Step: [7001/45466], Trn Acc: 0.00, Val Acc: 69.00, Trn Loss: 0.78, Val Loss: 0.73\n",
      "Epoch: [1/20], Step: [8001/45466], Trn Acc: 0.00, Val Acc: 68.56, Trn Loss: 0.78, Val Loss: 0.72\n",
      "Epoch: [1/20], Step: [9001/45466], Trn Acc: 0.00, Val Acc: 69.59, Trn Loss: 0.76, Val Loss: 0.72\n",
      "Epoch: [1/20], Step: [10001/45466], Trn Acc: 0.00, Val Acc: 68.87, Trn Loss: 0.77, Val Loss: 0.72\n",
      "Epoch: [1/20], Step: [11001/45466], Trn Acc: 0.00, Val Acc: 69.74, Trn Loss: 0.77, Val Loss: 0.71\n",
      "Epoch: [1/20], Step: [12001/45466], Trn Acc: 0.00, Val Acc: 70.76, Trn Loss: 0.76, Val Loss: 0.70\n",
      "Epoch: [1/20], Step: [13001/45466], Trn Acc: 0.00, Val Acc: 69.89, Trn Loss: 0.76, Val Loss: 0.71\n",
      "Epoch: [1/20], Step: [14001/45466], Trn Acc: 0.00, Val Acc: 69.86, Trn Loss: 0.76, Val Loss: 0.71\n",
      "Epoch: [1/20], Step: [15001/45466], Trn Acc: 0.00, Val Acc: 69.46, Trn Loss: 0.76, Val Loss: 0.72\n",
      "Epoch: [1/20], Step: [16001/45466], Trn Acc: 0.00, Val Acc: 68.56, Trn Loss: 0.75, Val Loss: 0.71\n",
      "Epoch: [1/20], Step: [17001/45466], Trn Acc: 0.00, Val Acc: 71.07, Trn Loss: 0.76, Val Loss: 0.70\n",
      "Epoch: [1/20], Step: [18001/45466], Trn Acc: 0.00, Val Acc: 70.92, Trn Loss: 0.76, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [19001/45466], Trn Acc: 0.00, Val Acc: 69.59, Trn Loss: 0.75, Val Loss: 0.72\n",
      "Epoch: [1/20], Step: [20001/45466], Trn Acc: 0.00, Val Acc: 70.17, Trn Loss: 0.76, Val Loss: 0.71\n",
      "Epoch: [1/20], Step: [21001/45466], Trn Acc: 0.00, Val Acc: 69.71, Trn Loss: 0.74, Val Loss: 0.71\n",
      "Epoch: [1/20], Step: [22001/45466], Trn Acc: 0.00, Val Acc: 70.98, Trn Loss: 0.76, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [23001/45466], Trn Acc: 0.00, Val Acc: 69.99, Trn Loss: 0.75, Val Loss: 0.70\n",
      "Epoch: [1/20], Step: [24001/45466], Trn Acc: 0.00, Val Acc: 69.71, Trn Loss: 0.75, Val Loss: 0.71\n",
      "Epoch: [1/20], Step: [25001/45466], Trn Acc: 0.00, Val Acc: 69.40, Trn Loss: 0.75, Val Loss: 0.71\n",
      "Epoch: [1/20], Step: [26001/45466], Trn Acc: 0.00, Val Acc: 71.63, Trn Loss: 0.75, Val Loss: 0.68\n",
      "Epoch: [1/20], Step: [27001/45466], Trn Acc: 0.00, Val Acc: 70.82, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [28001/45466], Trn Acc: 0.00, Val Acc: 70.61, Trn Loss: 0.75, Val Loss: 0.70\n",
      "Epoch: [1/20], Step: [29001/45466], Trn Acc: 0.00, Val Acc: 71.04, Trn Loss: 0.75, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [30001/45466], Trn Acc: 0.00, Val Acc: 70.67, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [31001/45466], Trn Acc: 0.00, Val Acc: 71.41, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [32001/45466], Trn Acc: 0.00, Val Acc: 70.36, Trn Loss: 0.74, Val Loss: 0.68\n",
      "Epoch: [1/20], Step: [33001/45466], Trn Acc: 0.00, Val Acc: 71.44, Trn Loss: 0.74, Val Loss: 0.67\n",
      "Epoch: [1/20], Step: [34001/45466], Trn Acc: 0.00, Val Acc: 71.81, Trn Loss: 0.74, Val Loss: 0.68\n",
      "Epoch: [1/20], Step: [35001/45466], Trn Acc: 0.00, Val Acc: 70.64, Trn Loss: 0.74, Val Loss: 0.68\n",
      "Epoch: [1/20], Step: [36001/45466], Trn Acc: 0.00, Val Acc: 71.57, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [37001/45466], Trn Acc: 0.00, Val Acc: 72.00, Trn Loss: 0.74, Val Loss: 0.68\n",
      "Epoch: [1/20], Step: [38001/45466], Trn Acc: 0.00, Val Acc: 71.88, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [39001/45466], Trn Acc: 0.00, Val Acc: 70.33, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [40001/45466], Trn Acc: 0.00, Val Acc: 72.90, Trn Loss: 0.73, Val Loss: 0.67\n",
      "Epoch: [1/20], Step: [41001/45466], Trn Acc: 0.00, Val Acc: 70.70, Trn Loss: 0.73, Val Loss: 0.68\n",
      "Epoch: [1/20], Step: [42001/45466], Trn Acc: 0.00, Val Acc: 71.57, Trn Loss: 0.74, Val Loss: 0.67\n",
      "Epoch: [1/20], Step: [43001/45466], Trn Acc: 0.00, Val Acc: 70.82, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [1/20], Step: [44001/45466], Trn Acc: 0.00, Val Acc: 71.10, Trn Loss: 0.74, Val Loss: 0.67\n",
      "Epoch: [1/20], Step: [45001/45466], Trn Acc: 0.00, Val Acc: 71.84, Trn Loss: 0.73, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [1001/45466], Trn Acc: 0.00, Val Acc: 70.98, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [2001/45466], Trn Acc: 0.00, Val Acc: 71.63, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [3001/45466], Trn Acc: 0.00, Val Acc: 71.29, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [4001/45466], Trn Acc: 0.00, Val Acc: 73.17, Trn Loss: 0.73, Val Loss: 0.66\n",
      "Epoch: [2/20], Step: [5001/45466], Trn Acc: 0.00, Val Acc: 71.16, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [6001/45466], Trn Acc: 0.00, Val Acc: 71.26, Trn Loss: 0.74, Val Loss: 0.68\n",
      "Epoch: [2/20], Step: [7001/45466], Trn Acc: 0.00, Val Acc: 71.97, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [8001/45466], Trn Acc: 0.00, Val Acc: 71.50, Trn Loss: 0.74, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [9001/45466], Trn Acc: 0.00, Val Acc: 73.02, Trn Loss: 0.73, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [10001/45466], Trn Acc: 0.00, Val Acc: 70.70, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [11001/45466], Trn Acc: 0.00, Val Acc: 72.83, Trn Loss: 0.73, Val Loss: 0.66\n",
      "Epoch: [2/20], Step: [12001/45466], Trn Acc: 0.00, Val Acc: 72.49, Trn Loss: 0.73, Val Loss: 0.68\n",
      "Epoch: [2/20], Step: [13001/45466], Trn Acc: 0.00, Val Acc: 72.18, Trn Loss: 0.73, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [14001/45466], Trn Acc: 0.00, Val Acc: 71.44, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [15001/45466], Trn Acc: 0.00, Val Acc: 72.37, Trn Loss: 0.74, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [16001/45466], Trn Acc: 0.00, Val Acc: 72.77, Trn Loss: 0.74, Val Loss: 0.66\n",
      "Epoch: [2/20], Step: [17001/45466], Trn Acc: 0.00, Val Acc: 73.21, Trn Loss: 0.73, Val Loss: 0.66\n",
      "Epoch: [2/20], Step: [18001/45466], Trn Acc: 0.00, Val Acc: 70.05, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [19001/45466], Trn Acc: 0.00, Val Acc: 70.30, Trn Loss: 0.74, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [20001/45466], Trn Acc: 0.00, Val Acc: 72.49, Trn Loss: 0.73, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [21001/45466], Trn Acc: 0.00, Val Acc: 72.74, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [22001/45466], Trn Acc: 0.00, Val Acc: 71.29, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [23001/45466], Trn Acc: 0.00, Val Acc: 71.07, Trn Loss: 0.73, Val Loss: 0.71\n",
      "Epoch: [2/20], Step: [24001/45466], Trn Acc: 0.00, Val Acc: 71.72, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [25001/45466], Trn Acc: 0.00, Val Acc: 72.09, Trn Loss: 0.73, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [26001/45466], Trn Acc: 0.00, Val Acc: 71.50, Trn Loss: 0.73, Val Loss: 0.68\n",
      "Epoch: [2/20], Step: [27001/45466], Trn Acc: 0.00, Val Acc: 73.24, Trn Loss: 0.73, Val Loss: 0.65\n",
      "Epoch: [2/20], Step: [28001/45466], Trn Acc: 0.00, Val Acc: 71.57, Trn Loss: 0.73, Val Loss: 0.68\n",
      "Epoch: [2/20], Step: [29001/45466], Trn Acc: 0.00, Val Acc: 70.76, Trn Loss: 0.73, Val Loss: 0.68\n",
      "Epoch: [2/20], Step: [30001/45466], Trn Acc: 0.00, Val Acc: 72.03, Trn Loss: 0.72, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [31001/45466], Trn Acc: 0.00, Val Acc: 73.02, Trn Loss: 0.73, Val Loss: 0.66\n",
      "Epoch: [2/20], Step: [32001/45466], Trn Acc: 0.00, Val Acc: 72.34, Trn Loss: 0.72, Val Loss: 0.68\n",
      "Epoch: [2/20], Step: [33001/45466], Trn Acc: 0.00, Val Acc: 71.63, Trn Loss: 0.73, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [34001/45466], Trn Acc: 0.00, Val Acc: 71.10, Trn Loss: 0.73, Val Loss: 0.70\n",
      "Epoch: [2/20], Step: [35001/45466], Trn Acc: 0.00, Val Acc: 72.25, Trn Loss: 0.73, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [36001/45466], Trn Acc: 0.00, Val Acc: 73.24, Trn Loss: 0.73, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [37001/45466], Trn Acc: 0.00, Val Acc: 71.35, Trn Loss: 0.72, Val Loss: 0.69\n",
      "Epoch: [2/20], Step: [38001/45466], Trn Acc: 0.00, Val Acc: 72.83, Trn Loss: 0.73, Val Loss: 0.67\n",
      "Epoch: [2/20], Step: [39001/45466], Trn Acc: 0.00, Val Acc: 73.51, Trn Loss: 0.73, Val Loss: 0.67\n"
     ]
    }
   ],
   "source": [
    "model = NN(in_size=300, hidden_size=100, num_classes=3, vocab=TEXT.vocab, kernel_size=1)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (batch) in enumerate(train_iter):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch.headline)\n",
    "        loss = F.cross_entropy(pred,batch.sentimentClass)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        val_period = 1000\n",
    "        if i > 0 and i % val_period == 0:\n",
    "            # validate\n",
    "            model.eval()\n",
    "#             trn_acc, trn_loss = test_model(snli_train_iter_for_val, model)\n",
    "#             trn_acc = None\n",
    "            val_acc, val_loss = test_model(test_iter, model)\n",
    "    \n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Trn Acc: {:.2f}, Val Acc: {:.2f}, Trn Loss: {:.2f}, Val Loss: {:.2f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, len(train_iter), 0, val_acc,\n",
    "                          running_loss/val_period, val_loss))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64195"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"news_val_torch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "news_train_df, news_val_df = train_test_split(news_df, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_val_df.to_csv(\"news_torch_experiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>sentimentClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1281950</th>\n",
       "      <td>CORRECTED-UPDATE 1-Snowden's father criticizes...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917675</th>\n",
       "      <td>Quarterly Results and Earnings Call Schedules,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829658</th>\n",
       "      <td>TEXT-S&amp;P release on Fannie Mae, Freddie Mac</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051799</th>\n",
       "      <td>COMSTOCK-ON FEB 29, CLOSED ON SALE OF SOME OF ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233417</th>\n",
       "      <td>RPT-MCDONALD'S &lt;MCD.N&gt; CFO SAYS TO RE-IMAGE 1,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  headline  sentimentClass\n",
       "1281950  CORRECTED-UPDATE 1-Snowden's father criticizes...              -1\n",
       "917675   Quarterly Results and Earnings Call Schedules,...               1\n",
       "829658         TEXT-S&P release on Fannie Mae, Freddie Mac               0\n",
       "1051799  COMSTOCK-ON FEB 29, CLOSED ON SALE OF SOME OF ...               0\n",
       "1233417  RPT-MCDONALD'S <MCD.N> CFO SAYS TO RE-IMAGE 1,...               0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"news_train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df[['headline',\n",
    "                   'sentimentClass',\n",
    "                   'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df = news_df[ (news_df['time']>='2015-01-01')]\n",
    "news_train_df = news_df[ (news_df['time']<'2015-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df = news_test_df[['headline',\n",
    "                             'sentimentClass']]\n",
    "news_train_df = news_train_df[['headline',\n",
    "                               'sentimentClass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "news_train_df, news_val_df = train_test_split(news_train_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train_df.to_csv('news_train_torch.csv', index=False)\n",
    "news_val_df.to_csv('news_val_torch.csv', index=False)\n",
    "news_test_df.to_csv('news_test_torch.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"news_train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df[['assetCodes', \n",
    "                    'assetName', \n",
    "                    'sentimentClass', \n",
    "                    'headline',\n",
    "                    'time',\n",
    "                    'sentimentNegative',\n",
    "                    'sentimentNeutral',\n",
    "                    'sentimentPositive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>sentimentClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China's Daqing pumps 43.41 mln tonnes of oil i...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEATURE-In kidnapping, finesse works best</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRESS DIGEST - Wall Street Journal - Jan 1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  sentimentClass\n",
       "0  China's Daqing pumps 43.41 mln tonnes of oil i...              -1\n",
       "1          FEATURE-In kidnapping, finesse works best              -1\n",
       "2         PRESS DIGEST - Wall Street Journal - Jan 1              -1\n",
       "3              PRESS DIGEST - New York Times - Jan 1              -1\n",
       "4              PRESS DIGEST - New York Times - Jan 1              -1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test_df = news_df[ (news_df['time']>='2015-01-01')]\n",
    "news_train_df = news_df[ (news_df['time']<'2015-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def genData(news_df):\n",
    "#     data = []\n",
    "#     target = []\n",
    "#     for index, row in news_df.iterrows():\n",
    "#         data.append(row['headline'])\n",
    "#         target.append([row['sentimentNegative'], row['sentimentNeutral'], row['sentimentPositive']])\n",
    "#     return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_targets = news_test_df['headline'].values.tolist(), \\\n",
    "                            news_test_df[['sentimentNegative', 'sentimentNeutral', 'sentimentPositive']].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "news_train_df_head = news_test_df.head(20000)\n",
    "# train_data, train_target = genData(news_train_df_head)\n",
    "train_data, train_targets = news_train_df_head['headline'].values.tolist(), \\\n",
    "                            news_train_df_head[['sentimentNegative', 'sentimentNeutral', 'sentimentPositive']].values.tolist()\n",
    "\n",
    "train_data, val_data, train_targets, val_targets = train_test_split(\n",
    "    train_data, train_targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #1 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d686ed0e91fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.6/site-packages/torchtext/data/example.py\u001b[0m in \u001b[0;36mfromlist\u001b[0;34m(cls, data, fields)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfromlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zip argument #1 must support iteration"
     ]
    }
   ],
   "source": [
    "torchtext.data.Example.fromlist(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
